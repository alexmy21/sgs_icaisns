{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HllSet Relational Algebra\n",
    "\n",
    "The **HyperLogLog (HLL)** algorithm is quite clever. It estimates the number of unique elements in a set of uniformly distributed random numbers by looking at the maximum number of trailing zeros in the binary form of each number. If you observe **n** as the maximum number of trailing zeros, then you can guess that there are about **2^n** distinct elements in the set.\n",
    "\n",
    "But there’s a catch — the estimate can vary a lot. So, to get a more accurate estimate, the HLL algorithm splits the multiset into several smaller subsets. For each subset, it finds the maximum number of trailing zeros and then uses a harmonic mean to combine these numbers, giving a better overall estimate of the total number of unique elements.\n",
    "\n",
    "The HLL data structure is represented as a **k-tuple \\( t = (n1, n2, . . . , ni, . . . , nk) \\)**, where each **\\( ni \\)** is the maximum number of trailing zeros for the i-th subset. This setup allows you to merge multiple HLLs without losing information. When you do merge them, the resultant HLL provides the same count of unique elements as if you had calculated it on the combined original datasets.\n",
    "\n",
    "However, HLLs have their limitations—they don’t support other set operations like **intersection**. To fix this, you can enhance the structure by using **bit-vectors** instead of just the **maximum number** of zeros in the tuple t. By using **bit-vectors** to keep track of all the trailing zeros for each subset, this improved structure, which we call **HllSets** (HyperLogLog Sets), **allows you to perform all set operations**.\n",
    "\n",
    "\n",
    "# References\n",
    "1. https://en.wikipedia.org/wiki/HyperLogLog\n",
    "2. https://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf\n",
    "3. https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf\n",
    "4. https://redis.io/docs/data-types/probabilistic/hyperloglogs/\n",
    "5. https://github.com/ascv/HyperLogLog/blob/master/README.md\n",
    "6. https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle\n",
    "7. https://en.wikipedia.org/wiki/Algebra_of_sets\n",
    "8. https://dl.acm.org/doi/10.1145/358396.358400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg\n",
    "# Pkg.activate(\".\")\n",
    "# Pkg.instantiate()\n",
    "# Pkg.add(\"CSV\")\n",
    "# Pkg.add(\"Arrow\")\n",
    "# Pkg.add(\"Tables\")\n",
    "# Pkg.add(\"JSON3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating HllSets and applying basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UInt32[0x00000002, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000001, 0x00000004, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000004, 0x00000000, 0x00000000, 0x00000000, 0x00000001, 0x00000001, 0x00000000, 0x00000000, 0x00000001, 0x00000000, 0x00000000, 0x00000002, 0x00000001, 0x00000000, 0x00000000, 0x00000000]\n",
      "10\n",
      "UInt32[0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000004, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000002, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000001, 0x00000000, 0x00000000, 0x00000004, 0x00000020, 0x00000000, 0x00000002, 0x00000002, 0x00000004, 0x00000000, 0x00000000, 0x00000002, 0x00000000, 0x00000000]\n",
      "12\n",
      "Size of hll1: 32; \n",
      "Size of hll1_seeded: 32\n"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "using FilePathsBase: extension, Path\n",
    "\n",
    "include(\"src/sets32.jl\")\n",
    "\n",
    "import .HllSets as set\n",
    "\n",
    "# Initialize test HllSets\n",
    "hll1 = set.HllSet{5}(); hll1_seeded = set.HllSet{5}()\n",
    "hll2 = set.HllSet{5}(); hll2_seeded = set.HllSet{5}()\n",
    "hll3 = set.HllSet{5}(); hll3_seeded = set.HllSet{5}()\n",
    "hll4 = set.HllSet{5}(); hll4_seeded = set.HllSet{5}()\n",
    "hll5 = set.HllSet{5}(); hll5_seeded = set.HllSet{5}()\n",
    "\n",
    "# Generate datasets from random strings\n",
    "s1 = Set(randstring(7) for _ in 1:10)\n",
    "s2 = Set(randstring(7) for _ in 1:15)\n",
    "s3 = Set(randstring(7) for _ in 1:100)\n",
    "s4 = Set(randstring(7) for _ in 1:20)\n",
    "s5 = Set(randstring(7) for _ in 1:130)\n",
    "\n",
    "# Add datasets to HllSets\n",
    "set.add!(hll1, s1); set.add!(hll1_seeded, s1, seed=123)\n",
    "set.add!(hll2, s2); set.add!(hll2_seeded, s2, seed=123)\n",
    "set.add!(hll3, s3); set.add!(hll3_seeded, s3, seed=123)\n",
    "set.add!(hll4, s4); set.add!(hll4_seeded, s4, seed=123)\n",
    "set.add!(hll5, s5); set.add!(hll5_seeded, s5, seed=123)\n",
    "\n",
    "println(hll1.counts, \"\\n\", count(hll1))\n",
    "println(hll1_seeded.counts, \"\\n\", count(hll1_seeded))\n",
    "\n",
    "println(\"Size of hll1: \", set.sizeof(hll1), \"; \\nSize of hll1_seeded: \", set.sizeof(hll1_seeded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 10\n",
      "15 : 13\n",
      "100 : 105\n",
      "20 : 24\n",
      "130 : 121\n",
      "\n",
      "union:\n",
      "275 : 295\n",
      "\n",
      "intersection (standard HllSet with seeded):\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Print cardinality of datasets and HllSets side by side\n",
    "println(length(s1), \" : \", count(hll1))\n",
    "println(length(s2), \" : \", count(hll2))\n",
    "println(length(s3), \" : \", count(hll3))\n",
    "println(length(s4), \" : \", count(hll4))\n",
    "println(length(s5), \" : \", count(hll5))\n",
    "\n",
    "# union\n",
    "println(\"\\nunion:\\n\", length(s1 ∪ s2 ∪ s3 ∪ s4 ∪ s5), \" : \", count(hll1 ∪ hll2 ∪ hll3 ∪ hll4 ∪ hll5), \"\\n\")\n",
    "\n",
    "# intersection\n",
    "println(\"intersection (standard HllSet with seeded):\\n\", count(hll1 ∩ hll1_seeded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HllSet Universes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = set.HllSet{5}(); A_123 = set.HllSet{5}()\n",
    "B = set.HllSet{5}(); B_123 = set.HllSet{5}()\n",
    "C = set.HllSet{5}(); C_123 = set.HllSet{5}()\n",
    "\n",
    "items_t1 = Set([\"string0\", \"string1\", \"string2\", \"string3\", \"string4\", \"string5\", \"string6\", \"string7\", \"string8\", \"string9\", \"string10\"])\n",
    "items_t2 = Set([\"string3\", \"string4\", \"string5\", \"string6\", \"string7\", \"string8\", \"string9\", \"string10\", \"string11\"])\n",
    "items_t3 = Set([\"string5\", \"string6\", \"string7\", \"string8\", \"string9\", \"string10\", \"string11\"])\n",
    "\n",
    "set.add!(A, items_t1); set.add!(A_123, items_t1, seed=123)\n",
    "set.add!(B, items_t2); set.add!(B_123, items_t2, seed=123)\n",
    "set.add!(C, items_t3); set.add!(C_123, items_t3, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U ∩ U_123: 2\n",
      "\n",
      "A: 11\n",
      "A_123: 12\n",
      "B: 10\n",
      "B_123: 11\n",
      "C: 7\n",
      "C_123: 8\n",
      "U: 12\n",
      "U_123: 14\n",
      "AB = A ∩ B: 9\n",
      "AB_123 = A_123 ∩ B_123: 10\n",
      "AC = A ∩ C: 6\n",
      "AC_123 = A_123 ∩ C_123: 7\n",
      "BC = B ∩ C: 7\n",
      "BC_123 = B_123 ∩ C_123: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Default and seeded HllSet Universes\n",
    "U = A ∪ B ∪ C; U_123 = A_123 ∪ B_123 ∪ C_123\n",
    "\n",
    "# Intersection of 2 Universes is Empty (almost)\n",
    "println(\"U ∩ U_123: \", count(U ∩ U_123), \"\\n\")\n",
    "\n",
    "println(\"A: \", count(A)); println(\"A_123: \", count(A_123))\n",
    "println(\"B: \", count(B)); println(\"B_123: \", count(B_123))\n",
    "println(\"C: \", count(C)); println(\"C_123: \", count(C_123))\n",
    "println(\"U: \", count(U)); println(\"U_123: \", count(U_123))\n",
    "\n",
    "println(\"AB = A ∩ B: \", count(A ∩ B)); println(\"AB_123 = A_123 ∩ B_123: \", count(A_123 ∩ B_123))\n",
    "println(\"AC = A ∩ C: \", count(A ∩ C)); println(\"AC_123 = A_123 ∩ C_123: \", count(A_123 ∩ C_123))\n",
    "println(\"BC = B ∩ C: \", count(B ∩ C)); println(\"BC_123 = B_123 ∩ C_123: \", count(B_123 ∩ C_123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Probabilities and Conditional Proabilities with HllSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A) = |A| / |U|: 0.9166666666666666\n",
      "P(A_123) = |A_123| / |U_123|: 0.8571428571428571\n",
      "\n",
      "P(B) = |B| / |U|: 0.8333333333333334\n",
      "P(B_123) = |B_123| / |U_123|: 0.7857142857142857\n",
      "\n",
      "P(C) = |C| / |U|: 0.5833333333333334\n",
      "P(C_123) = |C_123| / |U_123|: 0.5714285714285714\n",
      "\n",
      "\n",
      "P(A | B) = |AB| / |B|: 0.9\n",
      "P(A_123 | B_123) = |AB_123| / |B_123|: 0.9090909090909091\n",
      "\n",
      "P(B | A) = |AB| / |A|: 0.8181818181818182\n",
      "P(A_123 | A_123) = |AB_123| / |A_123|: 0.8333333333333334\n",
      "\n",
      "P(A | C) = |AC| / |C|: 0.8571428571428571\n",
      "P(A_123 | C_123) = |AC_123| / |C_123|: 0.875\n",
      "\n",
      "P(C | A) = |AC| / |A|: 0.5454545454545454\n",
      "P(A_123 | A_123) = |AC_123| / |A_123|: 0.5833333333333334\n",
      "\n",
      "\n",
      "P(B | C) = BC / C: 1.0\n",
      "P(C | B) = BC / B: 0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Probabilities\n",
    "println(\"P(A) = |A| / |U|: \", count(A) / count(U)); println(\"P(A_123) = |A_123| / |U_123|: \", count(A_123) / count(U_123), \"\\n\")\n",
    "println(\"P(B) = |B| / |U|: \", count(B) / count(U)); println(\"P(B_123) = |B_123| / |U_123|: \", count(B_123) / count(U_123), \"\\n\")\n",
    "println(\"P(C) = |C| / |U|: \", count(C) / count(U)); println(\"P(C_123) = |C_123| / |U_123|: \", count(C_123) / count(U_123), \"\\n\", \"\\n\")\n",
    "\n",
    "# Conditional Probabilities\n",
    "println(\"P(A | B) = |AB| / |B|: \", count(A ∩ B) / count(B)); println(\"P(A_123 | B_123) = |AB_123| / |B_123|: \", count(A_123 ∩ B_123) / count(B_123), \"\\n\")\n",
    "println(\"P(B | A) = |AB| / |A|: \", count(A ∩ B) / count(A)); println(\"P(A_123 | A_123) = |AB_123| / |A_123|: \", count(A_123 ∩ B_123) / count(A_123), \"\\n\")\n",
    "println(\"P(A | C) = |AC| / |C|: \", count(A ∩ C) / count(C)); println(\"P(A_123 | C_123) = |AC_123| / |C_123|: \", count(A_123 ∩ C_123) / count(C_123), \"\\n\")\n",
    "println(\"P(C | A) = |AC| / |A|: \", count(A ∩ C) / count(A)); println(\"P(A_123 | A_123) = |AC_123| / |A_123|: \", count(A_123 ∩ C_123) / count(A_123), \"\\n\", \"\\n\")\n",
    "\n",
    "println(\"P(B | C) = BC / C: \", count(B ∩ C) / count(C))\n",
    "println(\"P(C | B) = BC / B: \", count(B ∩ C) / count(B), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How Many Universes Can We Have?**\n",
    "\n",
    "The answer depends on the operating system we are using. For instance, in a 64-bit environment, there are (2^64 - 1) (over 18 quintillion, or approximately 1.8 × 10^19) distinct values available to be used as seeds for generating HllSets.\n",
    "\n",
    "If these universes are constructed from the same collection of original datasets but utilize different seed values for the hash function to build HllSets, they will be structurally very similar, if not nearly identical. This phenomenon is observed (as we see it in the provided code) in two universes and remains consistent for three or more universes as well.\n",
    "\n",
    "We refer to this phenomenon as **The Entanglement of HllSets**.\n",
    "\n",
    "**Within the framework of SGS, entanglement signifies that when identical data is fed into HllSets—defined by varying hash functions and potentially different precision parameters (P)—the resulting structures tend to be remarkably similar, if not identical.**\n",
    "\n",
    "Uncovering hidden structures requires considerable effort, especially when working with very large datasets. **HllSet Entanglement provides an opportunity to \"teleport\" insights discovered in one SGS to another SGS that has been fed with the same or similar data**. This transfer of knowledge can occur without the need to move any data or repeat the discovery process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other HllSet operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLL xor: 4\n",
      "hll_int: 9\n",
      "\n",
      "=====================================\n",
      "Comp 1: 3\n",
      "A: 11\n",
      "\n",
      "=====================================\n",
      "Comp 2: 1\n",
      "B: 10\n"
     ]
    }
   ],
   "source": [
    "hll_diff = set.set_xor(A, B)\n",
    "println(\"HLL xor: \", count(hll_diff))\n",
    "\n",
    "hll_int = intersect(A, B)\n",
    "\n",
    "println(\"hll_int: \", count(hll_int))\n",
    "\n",
    "println()\n",
    "println(\"=====================================\")\n",
    "hll_comp_1 = set.set_comp(A, B)\n",
    "println(\"Comp 1: \", count(hll_comp_1))\n",
    "println(\"A: \", count(A))\n",
    "\n",
    "println()\n",
    "println(\"=====================================\")\n",
    "hll_comp_2 = set.set_comp(B, A)\n",
    "println(\"Comp 2: \", count(hll_comp_2))\n",
    "println(\"B: \", count(B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
